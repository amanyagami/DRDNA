{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path added: /home/local/ASUAD/asing651/ResnetCifar10pytorchFI\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Specify the directory path you want to add\n",
    "path_to_add = \"/home/local/ASUAD/asing651/ResnetCifar10pytorchFI/\"\n",
    "\n",
    "# Resolve the absolute path and add it to sys.path\n",
    "sys.path.append(os.path.abspath(path_to_add))\n",
    "\n",
    "print(\"Path added:\", os.path.abspath(path_to_add))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1279966/135684216.py:290: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load('correct_data.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "\n",
      "Test set: Average loss: 0.3590, Accuracy: 1198/2000 (59.90%) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# from pytorchfi.core import fault_injection \n",
    "# from pytorchfi.neuron_error_models import random_neuron_inj\n",
    "\n",
    "import torch.nn as nn\n",
    "from collections import namedtuple\n",
    "# from pytorchfi import core\n",
    "import torch\n",
    "import os\n",
    "import torchattacks\n",
    "import copy\n",
    "import logging\n",
    "import pandas as pd\n",
    "from bisect import bisect_left\n",
    "from data.data import testset\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import csv\n",
    "from src.utils.helpers import device\n",
    "from src.models.resnet import resnet18\n",
    "from src.utils.customFI_methods import random_neuron_single_bit_inj_Aman\n",
    "from config import Lambda2,Lambda1,Lambda3,bins_num,cohortSize,path\n",
    "from src.utils.customFI_methods import single_bit_flip_func\n",
    "from scipy.stats import wasserstein_distance\n",
    "# from offlineProfiling import cohort_size\n",
    "# from pytorchfi.neuron_error_models import (\n",
    "#     random_inj_per_layer,\n",
    "#     random_inj_per_layer_batched,\n",
    "#     random_neuron_inj,\n",
    "#     random_neuron_inj_batched,\n",
    "#     random_neuron_single_bit_inj,\n",
    "#     random_neuron_single_bit_inj_batched,\n",
    "#     random_batch_element,\n",
    "#     random_neuron_location,\n",
    "#     #declare_neuron_fault_injection\n",
    "# )\n",
    "# os.environ['LOGLEVEL'] = 'DEBUG'  # Adjust logging level to capture DEBUG messages\n",
    "# logging.basicConfig(level=logging.DEBUG,\n",
    "#                     format='%(asctime)-15s %(levelname)s %(message)s',\n",
    "#                     handlers=[\n",
    "#                         logging.StreamHandler(sys.stdout),  # Log to console\n",
    "#                         logging.FileHandler('logfile.txt')  # Log to file\n",
    "#                     ])\n",
    "\n",
    "all_data = []\n",
    "df = pd.DataFrame()\n",
    "cohort_size =cohortSize\n",
    "final_dict = {}\n",
    "from config import update_histogram,reset_histogram,normalize_histogram,listtohistogram,TAU2processing,TAU3processing,abnormality_score2,abnormality_score3,abnormility_score1\n",
    "\n",
    "pathtoTau1 = path + \"/tau1.pkl\"\n",
    "pathtoTau2 = path + \"/tau2.pkl\"\n",
    "pathtoTau3 = path + \"/tau3.pkl\"\n",
    "pathtoOutput = path + \"/testwitadvPGDoutput.csv\"\n",
    "pathtoDetectionSites = path + \"/DetectionSites.txt\"\n",
    "\n",
    "activations= {}\n",
    "def get_activation(name):\n",
    "    def hook(model,input,output):\n",
    "        activations[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "def test_with_fault(model, tau1, tau2, tau3):\n",
    "    '''\n",
    "    tau1 -> profiled DNA of neurons  \n",
    "    TAU1 -> Layer wise (abnormality score of neurons added )\n",
    "    tau2 -> layer DNA from profiling \n",
    "    TAU2 -> layer DNA during inference -> then abnormality score layer wise \n",
    "    tau3 -> profiled min max of layer  (need to take from profiling)\n",
    "    TAU3 -> min max of a layer  -> the layer wise abnormality score\n",
    "\n",
    "    '''\n",
    "    TAU1 = {}\n",
    "    Temp2 = copy.deepcopy(tau2)\n",
    "    for layer_name in Temp2:\n",
    "        Temp2[layer_name] =reset_histogram(Temp2[layer_name])\n",
    "    TAU3 = {}\n",
    "    model.eval()\n",
    "    model.conv1.register_forward_hook(get_activation('conv1'))\n",
    "    model.bn1.register_forward_hook(get_activation('bn1'))\n",
    "    model.layer1[0].conv1.register_forward_hook(get_activation('layer1.0.conv1'))\n",
    "    model.layer1[0].bn1.register_forward_hook(get_activation('layer1.0.bn1'))\n",
    "    model.layer1[0].conv2.register_forward_hook(get_activation('layer1.0.conv2'))\n",
    "    model.layer1[0].bn2.register_forward_hook(get_activation('layer1.0.bn2'))\n",
    "    model.layer2[0].conv1.register_forward_hook(get_activation('layer2.0.conv1'))\n",
    "    model.layer2[0].bn1.register_forward_hook(get_activation('layer2.0.bn1'))\n",
    "    model.layer2[0].conv2.register_forward_hook(get_activation('layer2.0.conv2'))\n",
    "    model.layer2[0].bn2.register_forward_hook(get_activation('layer2.0.bn2'))\n",
    "    model.layer3[0].conv1.register_forward_hook(get_activation('layer3.0.conv1'))\n",
    "    model.layer3[0].bn1.register_forward_hook(get_activation('layer3.0.bn1'))\n",
    "    model.layer3[0].conv2.register_forward_hook(get_activation('layer3.0.conv2'))\n",
    "    model.layer3[0].bn2.register_forward_hook(get_activation('layer3.0.bn2'))\n",
    "    model.layer4[0].conv1.register_forward_hook(get_activation('layer4.0.conv1'))\n",
    "    model.layer4[0].bn1.register_forward_hook(get_activation('layer4.0.bn1'))\n",
    "    model.layer4[0].conv2.register_forward_hook(get_activation('layer4.0.conv2'))\n",
    "    model.layer4[0].bn2.register_forward_hook(get_activation('layer4.0.bn2'))\n",
    "    model.avgpool.register_forward_hook(get_activation('avgpool'))\n",
    "    model.fc.register_forward_hook(get_activation('fc'))\n",
    "\n",
    "    # b, layer, C, H, W, err_val = [0], [0], [0], [0], [0], [1000]\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    count= 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    with open(pathtoOutput, 'w') as file:\n",
    "        pass\n",
    "    TAU1List = {}\n",
    "    TAU2List = {}\n",
    "    TAU3List = {}\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            # pfi.reset_current_layer()\n",
    "            #single_input = inputs[0]  # Extract the first image in the batch\n",
    "            #outputs = corrupt_model(single_input.unsqueeze(0))\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            # print(outputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            flag = 0\n",
    "            if predicted.eq(targets).sum().item() == 0:\n",
    "                flag = 1\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            count += 1\n",
    "\n",
    "            TAU2 = copy.deepcopy(Temp2)\n",
    "\n",
    "            for layer_name in LayerNames:\n",
    "                TAU1[layer_name] = 0\n",
    "            \n",
    "            # TAU1\n",
    "            for neuron in selected_neurons:\n",
    "                layer_name,pos = neuron\n",
    "                #some layers dont have 4 dimenions so this check (eg Fc ->last layer resnet18)\n",
    "                if len(pos) > 2:       \n",
    "                    b,c,w,h=pos\n",
    "                    TAU1[layer_name] += abnormility_score1(activations[layer_name][b,c,w,h].item(),tau1[neuron])\n",
    "                else :\n",
    "                    w,h=pos\n",
    "                    TAU1[layer_name] += abnormility_score1(activations[layer_name][b,c,w,h].item(),tau1[neuron])\n",
    "\n",
    "            #TAU2\n",
    "        \n",
    "            \n",
    "            # print(Temp2['avgpool'])\n",
    "            for neuron in selected_neurons:\n",
    "                layer_name,pos = neuron\n",
    "            #some layers dont have 4 dimenions so this check (eg Fc ->last layer resnet18)\n",
    "                if len(pos) > 2:       \n",
    "                    b,c,w,h=pos\n",
    "                    TAU2[layer_name] = update_histogram(activations[layer_name][b,c,w,h].item(),TAU2[layer_name])\n",
    "                else :\n",
    "                    w,h=pos\n",
    "                    TAU2[layer_name] = update_histogram(activations[layer_name][w,h].item(),TAU2[layer_name])\n",
    "\n",
    "            for layer_name in TAU2 :\n",
    "                TAU2[layer_name] = abnormality_score2(TAU2[layer_name],tau2[layer_name])\n",
    "\n",
    "\n",
    "            #TAU3\n",
    "            for layer_name, tensor in activations.items():\n",
    "                    TAU3[layer_name] = activations[layer_name]\n",
    "            TAU3 = TAU3processing(TAU3,1)\n",
    "\n",
    "            for layer_name in TAU3:\n",
    "                TAU3[layer_name] = abnormality_score3(TAU3[layer_name],tau3[layer_name])\n",
    "\n",
    "            #total abnormality score\n",
    "            lambda1 = 1\n",
    "            lambda2 = 1\n",
    "            lambda3 = 1\n",
    "            Total_score= {}\n",
    "            prev = 0 \n",
    "            final_Scores = []\n",
    "            with open(pathtoOutput, mode='a', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                Val = []\n",
    "                for layer in LayerNames:\n",
    "                    Total_score[layer] = prev + lambda1 * TAU1[layer] +  lambda2 * TAU2[layer] + lambda3 * TAU3[layer]\n",
    "                    prev= Total_score[layer]\n",
    "                    Val += [(layer,TAU1[layer],TAU2[layer],TAU3[layer])]\n",
    "                writer.writerow(Val)\n",
    "            final_Scores += [prev]\n",
    "            TAU3List[count] = TAU3\n",
    "            TAU2List[count] = TAU2\n",
    "            TAU3List[count] = TAU1\n",
    "            if count %100 == 0:\n",
    "                print(count)\n",
    "            if count == 2000 :\n",
    "                break\n",
    "    with open('/home/local/ASUAD/asing651/ResnetCifar10pytorchFI/DRDNA/b10c32/TAU1adv.pkl', 'wb') as f:\n",
    "        pickle.dump(TAU1 ,f)\n",
    "    with open('/home/local/ASUAD/asing651/ResnetCifar10pytorchFI/DRDNA/b10c32/TAU2adv.pkl', 'wb') as f:\n",
    "        pickle.dump(TAU2 ,f)\n",
    "    with open('/home/local/ASUAD/asing651/ResnetCifar10pytorchFI/DRDNA/b10c32/TAU3adv.pkl', 'wb') as f:\n",
    "        pickle.dump(TAU3 ,f)\n",
    "\n",
    "    print(f'\\nTest set: Average loss: {test_loss/len(testloader):.4f}, Accuracy: {correct}/{total} ({100.*correct/total:.2f}%) \\n')\n",
    "\n",
    "\n",
    "\n",
    "def pgd_attack(model, images, labels, eps=0.01, alpha=0.01, iters=20) :\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "    ori_images = images.data\n",
    "        \n",
    "    for i in range(iters) :    \n",
    "        images.requires_grad = True\n",
    "        outputs = model(images)\n",
    "\n",
    "        model.zero_grad()\n",
    "        cost = loss(outputs, labels).to(device)\n",
    "        cost.backward()\n",
    "\n",
    "        adv_images = images + alpha*images.grad.sign()\n",
    "        eta = torch.clamp(adv_images - ori_images, min=-eps, max=eps)\n",
    "        images = torch.clamp(ori_images + eta, min=0, max=1).detach_()\n",
    "            \n",
    "    return images,labels\n",
    "\n",
    "def fgsm_attack(model, loss_fn, images, labels, epsilon):\n",
    "    # Set requires_grad attribute of images to True for gradient computation\n",
    "    \n",
    "    images = images.clone().detach().to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    images.requires_grad = True\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    # Forward pass\n",
    "    outputs = model(images)\n",
    "    loss = loss_fn(outputs, labels)\n",
    "    \n",
    "    # Zero all existing gradients\n",
    "    model.zero_grad()\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # Collect the sign of the gradients of the input images\n",
    "    sign_data_grad = images.grad.sign()\n",
    "    \n",
    "    # Create the perturbed image by adjusting each pixel\n",
    "    perturbed_images = images + epsilon * sign_data_grad\n",
    "    \n",
    "    # # Clamp the perturbed images to maintain [0,1] range\n",
    "    # perturbed_images = torch.clamp(perturbed_images, 0, 1)\n",
    "    \n",
    "    return perturbed_images, labels\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    net = resnet18(pretrained=True, progress=True)\n",
    "    num_ftrs = net.fc.in_features\n",
    "    #net.fc = nn.Linear(num_ftrs, 10)  # Modify the last layer to output 10 classes\n",
    "    net = net.to(device)\n",
    "\n",
    "\n",
    "    # batch_size = 1\n",
    "    # H = 32\n",
    "    # W = 32\n",
    "    # C = 3\n",
    "    # bit_pos = 1\n",
    "    # ranges = [9999,9999,9999,9999,9999,9999,999999999,9999,9999,9999,9999,9999,9999,9999,9999,9999,9999,9999,9999,9999]\n",
    "    # pfi = single_bit_flip_func(\n",
    "    #             net,\n",
    "    #             batch_size=batch_size,\n",
    "    #             input_shape=[C,H,W],\n",
    "    #             use_cuda=True,\n",
    "    #             bits=8,\n",
    "    #             random_batch=False,\n",
    "    #             bit_pos=bit_pos,\n",
    "    #         )\n",
    "\n",
    "    # fi_layer=5\n",
    "    # fi_c = 6\n",
    "    # fi_h = 7\n",
    "    # fi_w = 2\n",
    "    # Load the saved tensors\n",
    "    data = torch.load('correct_data.pt')\n",
    "    correct_inputs = data['inputs']\n",
    "    correct_targets = data['targets']\n",
    "\n",
    "    # # Recreate the TensorDataset\n",
    "    # new_test_dataset = TensorDataset(correct_inputs, correct_targets)\n",
    "   \n",
    "\n",
    "    adv_input, adv_labels = pgd_attack(net,data['inputs'], data['targets'])\n",
    "    new_test_dataset = TensorDataset(adv_input, adv_labels.clone().detach())\n",
    "\n",
    "\n",
    "    # Create a DataLoader\n",
    "    testloader = DataLoader(\n",
    "        new_test_dataset,\n",
    "        batch_size=1,  # Use the batch size you need\n",
    "        shuffle=False,\n",
    "        num_workers=0  # Adjust based on your environment\n",
    "    )\n",
    "    # net = random_neuron_single_bit_inj_Aman(pfi, ranges, fi_layer, fi_c, fi_h, fi_w,bit_pos = bit_pos)\n",
    "    selected_neurons = []\n",
    "    LayerNames = []\n",
    "    with open('DetectionSites.txt', 'r') as f:\n",
    "        for line in f:\n",
    "            layer_name, location = line.strip().split(',',1)\n",
    "            location = eval(location.strip()) \n",
    "            selected_neurons.append((layer_name, location))\n",
    "            if layer_name not in LayerNames:\n",
    "                LayerNames += [layer_name]\n",
    "\n",
    "        with open('tau1.pkl', 'rb') as f:\n",
    "            tau1 = pickle.load(f)\n",
    "        with open('tau2.pkl', 'rb') as f:\n",
    "            tau2 = pickle.load(f)\n",
    "        with open('tau3.pkl', 'rb') as f:\n",
    "            tau3  =pickle.load(f)\n",
    "        T2 = copy.deepcopy(tau2)\n",
    "        T1 = copy.deepcopy(tau1)\n",
    "        T3 = copy.deepcopy(tau3)\n",
    "        for layer_name in T2:\n",
    "            reset_histogram(T2[layer_name])\n",
    "\n",
    "        test_with_fault(net,T1,T2,T3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://ufldl.stanford.edu/housenumbers/test_32x32.mat to ./data/test_32x32.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64275384/64275384 [00:09<00:00, 6458650.55it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "\n",
      "Test set: Average loss: 0.3527, Accuracy: 213/2000 (10.65%) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pytorchfi.core import fault_injection \n",
    "from pytorchfi.neuron_error_models import random_neuron_inj\n",
    "import torch.nn as nn\n",
    "from collections import namedtuple\n",
    "from pytorchfi import core\n",
    "import torch\n",
    "import os\n",
    "import copy\n",
    "import logging\n",
    "import pandas as pd\n",
    "from bisect import bisect_left\n",
    "import pickle\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import csv\n",
    "from src.utils.helpers import device\n",
    "from src.models.resnet import resnet18\n",
    "from src.utils.customFI_methods import random_neuron_single_bit_inj_Aman\n",
    "from config import Lambda2,Lambda1,Lambda3,bins_num,cohortSize,path\n",
    "from src.utils.customFI_methods import single_bit_flip_func\n",
    "from scipy.stats import wasserstein_distance\n",
    "# from offlineProfiling import cohort_size\n",
    "from pytorchfi.neuron_error_models import (\n",
    "    random_inj_per_layer,\n",
    "    random_inj_per_layer_batched,\n",
    "    random_neuron_inj,\n",
    "    random_neuron_inj_batched,\n",
    "    random_neuron_single_bit_inj,\n",
    "    random_neuron_single_bit_inj_batched,\n",
    "    random_batch_element,\n",
    "    random_neuron_location,\n",
    "    #declare_neuron_fault_injection\n",
    ")\n",
    "# os.environ['LOGLEVEL'] = 'DEBUG'  # Adjust logging level to capture DEBUG messages\n",
    "# logging.basicConfig(level=logging.DEBUG,\n",
    "#                     format='%(asctime)-15s %(levelname)s %(message)s',\n",
    "#                     handlers=[\n",
    "#                         logging.StreamHandler(sys.stdout),  # Log to console\n",
    "#                         logging.FileHandler('logfile.txt')  # Log to file\n",
    "#                     ])\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import SVHN\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "all_data = []\n",
    "df = pd.DataFrame()\n",
    "cohort_size =cohortSize\n",
    "final_dict = {}\n",
    "from config import update_histogram,reset_histogram,normalize_histogram,listtohistogram,TAU2processing,TAU3processing,abnormality_score2,abnormality_score3,abnormility_score1\n",
    "\n",
    "pathtoTau1 = path + \"/tau1.pkl\"\n",
    "pathtoTau2 = path + \"/tau2.pkl\"\n",
    "pathtoTau3 = path + \"/tau3.pkl\"\n",
    "pathtoOutput = path + \"/testwitOODSVHNoutput.csv\"\n",
    "pathtoDetectionSites = path + \"/DetectionSites.txt\"\n",
    "\n",
    "activations= {}\n",
    "def get_activation(name):\n",
    "    def hook(model,input,output):\n",
    "        activations[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "def test_with_fault(model, tau1, tau2, tau3):\n",
    "    '''\n",
    "    tau1 -> profiled DNA of neurons  \n",
    "    TAU1 -> Layer wise (abnormality score of neurons added )\n",
    "    tau2 -> layer DNA from profiling \n",
    "    TAU2 -> layer DNA during inference -> then abnormality score layer wise \n",
    "    tau3 -> profiled min max of layer  (need to take from profiling)\n",
    "    TAU3 -> min max of a layer  -> the layer wise abnormality score\n",
    "\n",
    "    '''\n",
    "    TAU1 = {}\n",
    "    Temp2 = copy.deepcopy(tau2)\n",
    "    for layer_name in Temp2:\n",
    "        Temp2[layer_name] =reset_histogram(Temp2[layer_name])\n",
    "    TAU3 = {}\n",
    "    model.eval()\n",
    "    model.conv1.register_forward_hook(get_activation('conv1'))\n",
    "    model.bn1.register_forward_hook(get_activation('bn1'))\n",
    "    model.layer1[0].conv1.register_forward_hook(get_activation('layer1.0.conv1'))\n",
    "    model.layer1[0].bn1.register_forward_hook(get_activation('layer1.0.bn1'))\n",
    "    model.layer1[0].conv2.register_forward_hook(get_activation('layer1.0.conv2'))\n",
    "    model.layer1[0].bn2.register_forward_hook(get_activation('layer1.0.bn2'))\n",
    "    model.layer2[0].conv1.register_forward_hook(get_activation('layer2.0.conv1'))\n",
    "    model.layer2[0].bn1.register_forward_hook(get_activation('layer2.0.bn1'))\n",
    "    model.layer2[0].conv2.register_forward_hook(get_activation('layer2.0.conv2'))\n",
    "    model.layer2[0].bn2.register_forward_hook(get_activation('layer2.0.bn2'))\n",
    "    model.layer3[0].conv1.register_forward_hook(get_activation('layer3.0.conv1'))\n",
    "    model.layer3[0].bn1.register_forward_hook(get_activation('layer3.0.bn1'))\n",
    "    model.layer3[0].conv2.register_forward_hook(get_activation('layer3.0.conv2'))\n",
    "    model.layer3[0].bn2.register_forward_hook(get_activation('layer3.0.bn2'))\n",
    "    model.layer4[0].conv1.register_forward_hook(get_activation('layer4.0.conv1'))\n",
    "    model.layer4[0].bn1.register_forward_hook(get_activation('layer4.0.bn1'))\n",
    "    model.layer4[0].conv2.register_forward_hook(get_activation('layer4.0.conv2'))\n",
    "    model.layer4[0].bn2.register_forward_hook(get_activation('layer4.0.bn2'))\n",
    "    model.avgpool.register_forward_hook(get_activation('avgpool'))\n",
    "    model.fc.register_forward_hook(get_activation('fc'))\n",
    "\n",
    "    # b, layer, C, H, W, err_val = [0], [0], [0], [0], [0], [1000]\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    count= 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    with open(pathtoOutput, 'w') as file:\n",
    "        pass\n",
    "    TAU1List = {}\n",
    "    TAU2List = {}\n",
    "    TAU3List = {}\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            # pfi.reset_current_layer()\n",
    "            #single_input = inputs[0]  # Extract the first image in the batch\n",
    "            #outputs = corrupt_model(single_input.unsqueeze(0))\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            # print(outputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            flag = 0\n",
    "            if predicted.eq(targets).sum().item() == 0:\n",
    "                flag = 1\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            count += 1\n",
    "\n",
    "            TAU2 = copy.deepcopy(Temp2)\n",
    "\n",
    "            for layer_name in LayerNames:\n",
    "                TAU1[layer_name] = 0\n",
    "            \n",
    "            # TAU1\n",
    "            for neuron in selected_neurons:\n",
    "                layer_name,pos = neuron\n",
    "                #some layers dont have 4 dimenions so this check (eg Fc ->last layer resnet18)\n",
    "                if len(pos) > 2:       \n",
    "                    b,c,w,h=pos\n",
    "                    TAU1[layer_name] += abnormility_score1(activations[layer_name][b,c,w,h].item(),tau1[neuron])\n",
    "                else :\n",
    "                    w,h=pos\n",
    "                    TAU1[layer_name] += abnormility_score1(activations[layer_name][b,c,w,h].item(),tau1[neuron])\n",
    "\n",
    "            #TAU2\n",
    "        \n",
    "            \n",
    "            # print(Temp2['avgpool'])\n",
    "            for neuron in selected_neurons:\n",
    "                layer_name,pos = neuron\n",
    "            #some layers dont have 4 dimenions so this check (eg Fc ->last layer resnet18)\n",
    "                if len(pos) > 2:       \n",
    "                    b,c,w,h=pos\n",
    "                    TAU2[layer_name] = update_histogram(activations[layer_name][b,c,w,h].item(),TAU2[layer_name])\n",
    "                else :\n",
    "                    w,h=pos\n",
    "                    TAU2[layer_name] = update_histogram(activations[layer_name][w,h].item(),TAU2[layer_name])\n",
    "\n",
    "            for layer_name in TAU2 :\n",
    "                TAU2[layer_name] = abnormality_score2(TAU2[layer_name],tau2[layer_name])\n",
    "\n",
    "\n",
    "            #TAU3\n",
    "            for layer_name, tensor in activations.items():\n",
    "                    TAU3[layer_name] = activations[layer_name]\n",
    "            TAU3 = TAU3processing(TAU3,1)\n",
    "\n",
    "            for layer_name in TAU3:\n",
    "                TAU3[layer_name] = abnormality_score3(TAU3[layer_name],tau3[layer_name])\n",
    "\n",
    "            #total abnormality score\n",
    "            lambda1 = 1\n",
    "            lambda2 = 1\n",
    "            lambda3 = 1\n",
    "            Total_score= {}\n",
    "            prev = 0 \n",
    "            final_Scores = []\n",
    "            with open(pathtoOutput, mode='a', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                Val = []\n",
    "                for layer in LayerNames:\n",
    "                    Total_score[layer] = prev + lambda1 * TAU1[layer] +  lambda2 * TAU2[layer] + lambda3 * TAU3[layer]\n",
    "                    prev= Total_score[layer]\n",
    "                    Val += [(layer,TAU1[layer],TAU2[layer],TAU3[layer])]\n",
    "                writer.writerow(Val)\n",
    "            final_Scores += [prev]\n",
    "            TAU3List[count] = TAU3\n",
    "            TAU2List[count] = TAU2\n",
    "            TAU3List[count] = TAU1\n",
    "            if count %100 == 0:\n",
    "                print(count)\n",
    "            if count == 2000 :\n",
    "                break\n",
    "    with open('/home/local/ASUAD/asing651/ResnetCifar10pytorchFI/DRDNA/b10c32/TAU1adv.pkl', 'wb') as f:\n",
    "        pickle.dump(TAU1 ,f)\n",
    "    with open('/home/local/ASUAD/asing651/ResnetCifar10pytorchFI/DRDNA/b10c32/TAU2adv.pkl', 'wb') as f:\n",
    "        pickle.dump(TAU2 ,f)\n",
    "    with open('/home/local/ASUAD/asing651/ResnetCifar10pytorchFI/DRDNA/b10c32/TAU3adv.pkl', 'wb') as f:\n",
    "        pickle.dump(TAU3 ,f)\n",
    "\n",
    "    print(f'\\nTest set: Average loss: {test_loss/len(testloader):.4f}, Accuracy: {correct}/{total} ({100.*correct/total:.2f}%) \\n')\n",
    "\n",
    "def fgsm_attack(model, loss_fn, images, labels, epsilon):\n",
    "    # Set requires_grad attribute of images to True for gradient computation\n",
    "    \n",
    "    images = images.clone().detach().to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    images.requires_grad = True\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    # Forward pass\n",
    "    outputs = model(images)\n",
    "    loss = loss_fn(outputs, labels)\n",
    "    \n",
    "    # Zero all existing gradients\n",
    "    model.zero_grad()\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # Collect the sign of the gradients of the input images\n",
    "    sign_data_grad = images.grad.sign()\n",
    "    \n",
    "    # Create the perturbed image by adjusting each pixel\n",
    "    perturbed_images = images + epsilon * sign_data_grad\n",
    "    \n",
    "    # Clamp the perturbed images to maintain [0,1] range\n",
    "    perturbed_images = torch.clamp(perturbed_images, 0, 1)\n",
    "    \n",
    "    return perturbed_images, labels\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    net = resnet18(pretrained=True, progress=True)\n",
    "    num_ftrs = net.fc.in_features\n",
    "    #net.fc = nn.Linear(num_ftrs, 10)  # Modify the last layer to output 10 classes\n",
    "    net = net.to(device)\n",
    "\n",
    "\n",
    "    # batch_size = 1\n",
    "    # H = 32\n",
    "    # W = 32\n",
    "    # C = 3\n",
    "    # bit_pos = 1\n",
    "    # ranges = [9999,9999,9999,9999,9999,9999,999999999,9999,9999,9999,9999,9999,9999,9999,9999,9999,9999,9999,9999,9999]\n",
    "    # pfi = single_bit_flip_func(\n",
    "    #             net,\n",
    "    #             batch_size=batch_size,\n",
    "    #             input_shape=[C,H,W],\n",
    "    #             use_cuda=True,\n",
    "    #             bits=8,\n",
    "    #             random_batch=False,\n",
    "    #             bit_pos=bit_pos,\n",
    "    #         )\n",
    "\n",
    "    # fi_layer=5\n",
    "    # fi_c = 6\n",
    "    # fi_h = 7\n",
    "    # fi_w = 2\n",
    "    # Load the saved tensors\n",
    "    # data = torch.load('correct_data.pt')\n",
    "    # correct_inputs = data['inputs']\n",
    "    # correct_targets = data['targets']\n",
    "\n",
    "    # # Recreate the TensorDataset\n",
    "    # new_test_dataset = TensorDataset(correct_inputs, correct_targets)\n",
    "    \n",
    "    #fgsm attack on the dataset\n",
    "    # adv_input, adv_labels = fgsm_attack(net,nn.CrossEntropyLoss(),data['inputs'], data['targets'],epsilon=0.009)\n",
    "    # new_test_dataset = TensorDataset(adv_input, adv_labels.clone().detach())\n",
    "    # Create a DataLoader\n",
    "    \n",
    "    # Define transformations for the dataset\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize with mean and std for RGB channels\n",
    "    ])\n",
    "\n",
    "    # Download and load the test dataset\n",
    "    test_data = SVHN(root='./data', split='test', transform=transform, download=True)\n",
    "    testloader = DataLoader(test_data, batch_size=1, shuffle=False)\n",
    "\n",
    "    # testloader = DataLoader(\n",
    "    #     new_test_dataset,\n",
    "    #     batch_size=1,  # Use the batch size you need\n",
    "    #     shuffle=False,\n",
    "    #     num_workers=0  # Adjust based on your environment\n",
    "    # )\n",
    "    # net = random_neuron_single_bit_inj_Aman(pfi, ranges, fi_layer, fi_c, fi_h, fi_w,bit_pos = bit_pos)\n",
    "    selected_neurons = []\n",
    "    LayerNames = []\n",
    "    with open('DetectionSites.txt', 'r') as f:\n",
    "        for line in f:\n",
    "            layer_name, location = line.strip().split(',',1)\n",
    "            location = eval(location.strip()) \n",
    "            selected_neurons.append((layer_name, location))\n",
    "            if layer_name not in LayerNames:\n",
    "                LayerNames += [layer_name]\n",
    "\n",
    "        with open('tau1.pkl', 'rb') as f:\n",
    "            tau1 = pickle.load(f)\n",
    "        with open('tau2.pkl', 'rb') as f:\n",
    "            tau2 = pickle.load(f)\n",
    "        with open('tau3.pkl', 'rb') as f:\n",
    "            tau3  =pickle.load(f)\n",
    "        T2 = copy.deepcopy(tau2)\n",
    "        T1 = copy.deepcopy(tau1)\n",
    "        T3 = copy.deepcopy(tau3)\n",
    "        for layer_name in T2:\n",
    "            reset_histogram(T2[layer_name])\n",
    "\n",
    "        test_with_fault(net,T1,T2,T3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1279966/2427907071.py:326: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load('correct_data.pt')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "\n",
      "Test set: Average loss: 0.3357, Accuracy: 1197/2000 (59.85%) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from pytorchfi.core import fault_injection \n",
    "from pytorchfi.neuron_error_models import random_neuron_inj\n",
    "import torch.nn as nn\n",
    "from collections import namedtuple\n",
    "from pytorchfi import core\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import logging\n",
    "import pandas as pd\n",
    "from bisect import bisect_left\n",
    "import pickle\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import csv\n",
    "from src.utils.helpers import device\n",
    "from torchattacks import FGSM, PGD, CW, AutoAttack\n",
    "from src.models.resnet import resnet18\n",
    "from src.utils.customFI_methods import random_neuron_single_bit_inj_Aman\n",
    "from config import Lambda2,Lambda1,Lambda3,bins_num,cohortSize,path\n",
    "from src.utils.customFI_methods import single_bit_flip_func\n",
    "from scipy.stats import wasserstein_distance\n",
    "# from offlineProfiling import cohort_size\n",
    "from pytorchfi.neuron_error_models import (\n",
    "    random_inj_per_layer,\n",
    "    random_inj_per_layer_batched,\n",
    "    random_neuron_inj,\n",
    "    random_neuron_inj_batched,\n",
    "    random_neuron_single_bit_inj,\n",
    "    random_neuron_single_bit_inj_batched,\n",
    "    random_batch_element,\n",
    "    random_neuron_location,\n",
    "    #declare_neuron_fault_injection\n",
    ")\n",
    "# os.environ['LOGLEVEL'] = 'DEBUG'  # Adjust logging level to capture DEBUG messages\n",
    "# logging.basicConfig(level=logging.DEBUG,\n",
    "#                     format='%(asctime)-15s %(levelname)s %(message)s',\n",
    "#                     handlers=[\n",
    "#                         logging.StreamHandler(sys.stdout),  # Log to console\n",
    "#                         logging.FileHandler('logfile.txt')  # Log to file\n",
    "#                     ])\n",
    "\n",
    "all_data = []\n",
    "df = pd.DataFrame()\n",
    "cohort_size =cohortSize\n",
    "final_dict = {}\n",
    "from config import update_histogram,reset_histogram,normalize_histogram,listtohistogram,TAU2processing,TAU3processing,abnormality_score2,abnormality_score3,abnormility_score1\n",
    "\n",
    "pathtoTau1 = path + \"/tau1.pkl\"\n",
    "pathtoTau2 = path + \"/tau2.pkl\"\n",
    "pathtoTau3 = path + \"/tau3.pkl\"\n",
    "pathtoOutput = path + \"/testwithadvfgsmoutput.csv\"\n",
    "pathtoDetectionSites = path + \"/DetectionSites.txt\"\n",
    "\n",
    "activations= {}\n",
    "def get_activation(name):\n",
    "    def hook(model,input,output):\n",
    "        activations[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "def test_with_fault(model, tau1, tau2, tau3):\n",
    "    '''\n",
    "    tau1 -> profiled DNA of neurons  \n",
    "    TAU1 -> Layer wise (abnormality score of neurons added )\n",
    "    tau2 -> layer DNA from profiling \n",
    "    TAU2 -> layer DNA during inference -> then abnormality score layer wise \n",
    "    tau3 -> profiled min max of layer  (need to take from profiling)\n",
    "    TAU3 -> min max of a layer  -> the layer wise abnormality score\n",
    "\n",
    "    '''\n",
    "    TAU1 = {}\n",
    "    Temp2 = copy.deepcopy(tau2)\n",
    "    for layer_name in Temp2:\n",
    "        Temp2[layer_name] =reset_histogram(Temp2[layer_name])\n",
    "    TAU3 = {}\n",
    "    model.eval()\n",
    "    model.conv1.register_forward_hook(get_activation('conv1'))\n",
    "    model.bn1.register_forward_hook(get_activation('bn1'))\n",
    "    model.layer1[0].conv1.register_forward_hook(get_activation('layer1.0.conv1'))\n",
    "    model.layer1[0].bn1.register_forward_hook(get_activation('layer1.0.bn1'))\n",
    "    model.layer1[0].conv2.register_forward_hook(get_activation('layer1.0.conv2'))\n",
    "    model.layer1[0].bn2.register_forward_hook(get_activation('layer1.0.bn2'))\n",
    "    model.layer2[0].conv1.register_forward_hook(get_activation('layer2.0.conv1'))\n",
    "    model.layer2[0].bn1.register_forward_hook(get_activation('layer2.0.bn1'))\n",
    "    model.layer2[0].conv2.register_forward_hook(get_activation('layer2.0.conv2'))\n",
    "    model.layer2[0].bn2.register_forward_hook(get_activation('layer2.0.bn2'))\n",
    "    model.layer3[0].conv1.register_forward_hook(get_activation('layer3.0.conv1'))\n",
    "    model.layer3[0].bn1.register_forward_hook(get_activation('layer3.0.bn1'))\n",
    "    model.layer3[0].conv2.register_forward_hook(get_activation('layer3.0.conv2'))\n",
    "    model.layer3[0].bn2.register_forward_hook(get_activation('layer3.0.bn2'))\n",
    "    model.layer4[0].conv1.register_forward_hook(get_activation('layer4.0.conv1'))\n",
    "    model.layer4[0].bn1.register_forward_hook(get_activation('layer4.0.bn1'))\n",
    "    model.layer4[0].conv2.register_forward_hook(get_activation('layer4.0.conv2'))\n",
    "    model.layer4[0].bn2.register_forward_hook(get_activation('layer4.0.bn2'))\n",
    "    model.avgpool.register_forward_hook(get_activation('avgpool'))\n",
    "    model.fc.register_forward_hook(get_activation('fc'))\n",
    "\n",
    "    # b, layer, C, H, W, err_val = [0], [0], [0], [0], [0], [1000]\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    count= 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    with open(pathtoOutput, 'w') as file:\n",
    "        pass\n",
    "    TAU1List = {}\n",
    "    TAU2List = {}\n",
    "    TAU3List = {}\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            # pfi.reset_current_layer()\n",
    "            #single_input = inputs[0]  # Extract the first image in the batch\n",
    "            #outputs = corrupt_model(single_input.unsqueeze(0))\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            # print(outputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            flag = 0\n",
    "            if predicted.eq(targets).sum().item() == 0:\n",
    "                flag = 1\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            count += 1\n",
    "\n",
    "            TAU2 = copy.deepcopy(Temp2)\n",
    "\n",
    "            for layer_name in LayerNames:\n",
    "                TAU1[layer_name] = 0\n",
    "            \n",
    "            # TAU1\n",
    "            for neuron in selected_neurons:\n",
    "                layer_name,pos = neuron\n",
    "                #some layers dont have 4 dimenions so this check (eg Fc ->last layer resnet18)\n",
    "                if len(pos) > 2:       \n",
    "                    b,c,w,h=pos\n",
    "                    TAU1[layer_name] += abnormility_score1(activations[layer_name][b,c,w,h].item(),tau1[neuron])\n",
    "                else :\n",
    "                    w,h=pos\n",
    "                    TAU1[layer_name] += abnormility_score1(activations[layer_name][b,c,w,h].item(),tau1[neuron])\n",
    "\n",
    "            #TAU2\n",
    "        \n",
    "            \n",
    "            # print(Temp2['avgpool'])\n",
    "            for neuron in selected_neurons:\n",
    "                layer_name,pos = neuron\n",
    "            #some layers dont have 4 dimenions so this check (eg Fc ->last layer resnet18)\n",
    "                if len(pos) > 2:       \n",
    "                    b,c,w,h=pos\n",
    "                    TAU2[layer_name] = update_histogram(activations[layer_name][b,c,w,h].item(),TAU2[layer_name])\n",
    "                else :\n",
    "                    w,h=pos\n",
    "                    TAU2[layer_name] = update_histogram(activations[layer_name][w,h].item(),TAU2[layer_name])\n",
    "\n",
    "            for layer_name in TAU2 :\n",
    "                TAU2[layer_name] = abnormality_score2(TAU2[layer_name],tau2[layer_name])\n",
    "\n",
    "\n",
    "            #TAU3\n",
    "            for layer_name, tensor in activations.items():\n",
    "                    TAU3[layer_name] = activations[layer_name]\n",
    "            TAU3 = TAU3processing(TAU3,1)\n",
    "\n",
    "            for layer_name in TAU3:\n",
    "                TAU3[layer_name] = abnormality_score3(TAU3[layer_name],tau3[layer_name])\n",
    "\n",
    "            #total abnormality score\n",
    "            lambda1 = 1\n",
    "            lambda2 = 1\n",
    "            lambda3 = 1\n",
    "            Total_score= {}\n",
    "            prev = 0 \n",
    "            final_Scores = []\n",
    "            with open(pathtoOutput, mode='a', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                Val = []\n",
    "                for layer in LayerNames:\n",
    "                    Total_score[layer] = prev + lambda1 * TAU1[layer] +  lambda2 * TAU2[layer] + lambda3 * TAU3[layer]\n",
    "                    prev= Total_score[layer]\n",
    "                    Val += [(layer,TAU1[layer],TAU2[layer],TAU3[layer])]\n",
    "                writer.writerow(Val)\n",
    "            final_Scores += [prev]\n",
    "            TAU3List[count] = TAU3\n",
    "            TAU2List[count] = TAU2\n",
    "            TAU3List[count] = TAU1\n",
    "            if count %100 == 0:\n",
    "                print(count)\n",
    "            if count == 2000 :\n",
    "                break\n",
    "    with open('/home/local/ASUAD/asing651/ResnetCifar10pytorchFI/DRDNA/b10c32/TAU1adv.pkl', 'wb') as f:\n",
    "        pickle.dump(TAU1 ,f)\n",
    "    with open('/home/local/ASUAD/asing651/ResnetCifar10pytorchFI/DRDNA/b10c32/TAU2adv.pkl', 'wb') as f:\n",
    "        pickle.dump(TAU2 ,f)\n",
    "    with open('/home/local/ASUAD/asing651/ResnetCifar10pytorchFI/DRDNA/b10c32/TAU3adv.pkl', 'wb') as f:\n",
    "        pickle.dump(TAU3 ,f)\n",
    "\n",
    "    print(f'\\nTest set: Average loss: {test_loss/len(testloader):.4f}, Accuracy: {correct}/{total} ({100.*correct/total:.2f}%) \\n')\n",
    "\n",
    "\n",
    "def fgsm_attack(model, loss, images, labels, eps) :\n",
    "    \n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    images.requires_grad = True\n",
    "            \n",
    "    outputs = model(images)\n",
    "    \n",
    "    model.zero_grad()\n",
    "    cost = loss(outputs, labels).to(device)\n",
    "    cost.backward()\n",
    "    \n",
    "    attack_images = images + eps*images.grad.sign()\n",
    "    attack_images = torch.clamp(attack_images, 0, 1)\n",
    "    \n",
    "    return attack_images,labels\n",
    "\n",
    "def fgsm_attack2(model, loss_fn, images1, labels1, epsilon):\n",
    "    # Set requires_grad attribute of images to True for gradient computation\n",
    "    \n",
    "    images = copy.deepcopy(images1).to(device)\n",
    "    labels = copy.deepcopy(labels1).to(device)\n",
    "    perturbed_images =  torch.empty_like(correct_inputs)\n",
    "    num_classes = 10\n",
    "    atk = FGSM(model, eps=0.007)\n",
    "    for idx in range(len(images)):\n",
    "    # for idx in range(1):\n",
    "        image = images[idx]\n",
    "        label = labels[idx]\n",
    "        image = image.unsqueeze(0)\n",
    "        label = label.unsqueeze(0)\n",
    "        min = image.min()\n",
    "        max = image.max()\n",
    "        normalized_image = (image - min) / (max - min)\n",
    "        adv_image = atk(normalized_image,label) \n",
    "\n",
    "        denormalized_image = adv_image * (max - min) + min\n",
    "        adv_image = adv_image.squeeze(0)\n",
    "        label = label.squeeze(0)\n",
    "        perturbed_images[idx] = adv_image\n",
    "    \n",
    "   \n",
    "    return perturbed_images, labels\n",
    "\n",
    "def preprocess_image(tensor1):\n",
    "    \"\"\"\n",
    "    Converts a tensor image to a numpy array for visualization.\n",
    "    Assumes tensor is in (C, H, W) format.\n",
    "    \"\"\"\n",
    "    # Move the tensor to CPU and convert to numpy\n",
    "    image = tensor1.clone().detach().cpu().numpy()\n",
    "    \n",
    "    # If the tensor is normalized, you might need to unnormalize it\n",
    "    # For example, if normalized with mean and std:\n",
    "    # mean = np.array([0.485, 0.456, 0.406])\n",
    "    # std = np.array([0.229, 0.224, 0.225])\n",
    "    # image = (image * std[:, None, None]) + mean[:, None, None]\n",
    "    \n",
    "    # Transpose from (C, H, W) to (H, W, C)\n",
    "    image = np.transpose(image, (1, 2, 0))\n",
    "    \n",
    "    # Clip the image to [0, 1] range\n",
    "    image = np.clip(image, 0, 1)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def show_single_image(tensor, label, classes=None, flag = 0 ):\n",
    "    \"\"\"\n",
    "    Displays a single image with its label.\n",
    "\n",
    "    Args:\n",
    "        tensor (Tensor): Image tensor of shape (C, H, W).\n",
    "        label (int): Label index.\n",
    "        classes (list): List of class names.\n",
    "    \"\"\"\n",
    "    image = preprocess_image(tensor)\n",
    "    \n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(image)\n",
    "    if classes:\n",
    "        plt.title(classes[label])\n",
    "    else:\n",
    "        plt.title(f\"Label: {label}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    if flag == 0:\n",
    "        plt.savefig('/home/local/ASUAD/asing651/ResnetCifar10pytorchFI/DRDNA/b10c32/imageBeforeAdv.png')\n",
    "    if flag == 1:\n",
    "        plt.savefig('/home/local/ASUAD/asing651/ResnetCifar10pytorchFI/DRDNA/b10c32/imageAfterAdv.png')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    net = resnet18(pretrained=True, progress=True)\n",
    "    num_ftrs = net.fc.in_features\n",
    "    #net.fc = nn.Linear(num_ftrs, 10)  # Modify the last layer to output 10 classes\n",
    "    net = net.to(device)\n",
    "\n",
    "\n",
    "    # batch_size = 1\n",
    "    # H = 32\n",
    "    # W = 32\n",
    "    # C = 3\n",
    "    # bit_pos = 1\n",
    "    # ranges = [9999,9999,9999,9999,9999,9999,999999999,9999,9999,9999,9999,9999,9999,9999,9999,9999,9999,9999,9999,9999]\n",
    "    # pfi = single_bit_flip_func(\n",
    "    #             net,\n",
    "    #             batch_size=batch_size,\n",
    "    #             input_shape=[C,H,W],\n",
    "    #             use_cuda=True,\n",
    "    #             bits=8,\n",
    "    #             random_batch=False,\n",
    "    #             bit_pos=bit_pos,\n",
    "    #         )\n",
    "\n",
    "    # fi_layer=5\n",
    "    # fi_c = 6\n",
    "    # fi_h = 7\n",
    "    # fi_w = 2\n",
    "    # Load the saved tensors\n",
    "    data = torch.load('correct_data.pt')\n",
    "    correct_inputs = data['inputs']\n",
    "    correct_targets = data['targets']\n",
    "\n",
    "    # # Recreate the TensorDataset\n",
    "    # new_test_dataset = TensorDataset(correct_inputs, correct_targets)\n",
    "    \n",
    "    #fgsm attack on the dataset\n",
    "    show_single_image(correct_inputs[0], correct_targets[0], None,0)\n",
    "    adv_input, adv_labels = fgsm_attack(net,nn.CrossEntropyLoss(),data['inputs'], data['targets'],eps=0.003)\n",
    "    show_single_image(adv_input[0], correct_targets[0], None,1)\n",
    "    new_test_dataset = TensorDataset(adv_input, adv_labels.clone().detach())\n",
    "    # new_test_dataset = TensorDataset(correct_inputs, correct_targets)\n",
    "    # Create a DataLoader\n",
    "    testloader = DataLoader(\n",
    "        new_test_dataset,\n",
    "        batch_size=1,  # Use the batch size you need\n",
    "        shuffle=False,\n",
    "        num_workers=0  # Adjust based on your environment\n",
    "    )\n",
    "    # net = random_neuron_single_bit_inj_Aman(pfi, ranges, fi_layer, fi_c, fi_h, fi_w,bit_pos = bit_pos)\n",
    "    selected_neurons = []\n",
    "    LayerNames = []\n",
    "    with open('DetectionSites.txt', 'r') as f:\n",
    "        for line in f:\n",
    "            layer_name, location = line.strip().split(',',1)\n",
    "            location = eval(location.strip()) \n",
    "            selected_neurons.append((layer_name, location))\n",
    "            if layer_name not in LayerNames:\n",
    "                LayerNames += [layer_name]\n",
    "\n",
    "        with open('tau1.pkl', 'rb') as f:\n",
    "            tau1 = pickle.load(f)\n",
    "        with open('tau2.pkl', 'rb') as f:\n",
    "            tau2 = pickle.load(f)\n",
    "        with open('tau3.pkl', 'rb') as f:\n",
    "            tau3  =pickle.load(f)\n",
    "        T2 = copy.deepcopy(tau2)\n",
    "        T1 = copy.deepcopy(tau1)\n",
    "        T3 = copy.deepcopy(tau3)\n",
    "        for layer_name in T2:\n",
    "            reset_histogram(T2[layer_name])\n",
    "\n",
    "        test_with_fault(net,T1,T2,T3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DRDNA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
